{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "utils2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOY+JnxW+I51MfOgD1A3IbN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sedol1339/voice_score/blob/main/utils2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_qwEC6QkYtzR"
      },
      "outputs": [],
      "source": [
        "URL = 'https://storage.googleapis.com/oleg-zyablov/misc/VoiceMOS'\n",
        "!wget -q {URL}/main.zip\n",
        "!wget -q {URL}/ood.zip\n",
        "!wget -q {URL}/data_with_annotators.csv\n",
        "!wget -q {URL}/data.csv\n",
        "!unzip -q -o main.zip && rm main.zip\n",
        "!unzip -q -o ood.zip && rm ood.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "data = pd.read_csv('data.csv')\n",
        "data.sample(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "orw71d61cK1Y",
        "outputId": "ea7c2976-a1e3-4344-8cf9-10977fdb5e23"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-24c309d0-7d0f-425e-927d-d8db0cb8708e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subset</th>\n",
              "      <th>system</th>\n",
              "      <th>utterance</th>\n",
              "      <th>file</th>\n",
              "      <th>file_exists</th>\n",
              "      <th>score_mean</th>\n",
              "      <th>score_std</th>\n",
              "      <th>n_scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3664</th>\n",
              "      <td>train</td>\n",
              "      <td>sys9d400</td>\n",
              "      <td>utt34664a2</td>\n",
              "      <td>sys9d400-utt34664a2.wav</td>\n",
              "      <td>True</td>\n",
              "      <td>4.000</td>\n",
              "      <td>0.9258</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5767</th>\n",
              "      <td>train</td>\n",
              "      <td>sysff05c</td>\n",
              "      <td>utt4fd1f30</td>\n",
              "      <td>sysff05c-utt4fd1f30.wav</td>\n",
              "      <td>True</td>\n",
              "      <td>2.625</td>\n",
              "      <td>0.9161</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5401</th>\n",
              "      <td>train</td>\n",
              "      <td>sysec937</td>\n",
              "      <td>uttb28aa53</td>\n",
              "      <td>sysec937-uttb28aa53.wav</td>\n",
              "      <td>True</td>\n",
              "      <td>2.375</td>\n",
              "      <td>0.9161</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24c309d0-7d0f-425e-927d-d8db0cb8708e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24c309d0-7d0f-425e-927d-d8db0cb8708e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24c309d0-7d0f-425e-927d-d8db0cb8708e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     subset    system   utterance  ... score_mean  score_std  n_scores\n",
              "3664  train  sys9d400  utt34664a2  ...      4.000     0.9258         8\n",
              "5767  train  sysff05c  utt4fd1f30  ...      2.625     0.9161         8\n",
              "5401  train  sysec937  uttb28aa53  ...      2.375     0.9161         8\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "train_and_val = data[data.subset.isin(['train', 'val'])]\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
        "data['fold'] = None\n",
        "for i, (train, val) in enumerate(kf.split(train_and_val)):\n",
        "  indices = train_and_val.index[val]\n",
        "  data.loc[indices, 'fold'] = i"
      ],
      "metadata": {
        "id": "UVgZq-B6MQQl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchaudio\n",
        "import os, base64\n",
        "from IPython import display\n",
        "\n",
        "def get_waveform(wav_file):\n",
        "  waveform, sample_rate = torchaudio.load(f'wav/{wav_file}')\n",
        "  assert sample_rate == 16000\n",
        "  return waveform[0]\n",
        "\n",
        "def get_spectrogram(waveform, **kwargs):\n",
        "  return torchaudio.transforms.Spectrogram(**kwargs)(waveform)\n",
        "\n",
        "def show_audio(file_path, width=300):\n",
        "  audio = open(file_path, 'rb').read()\n",
        "  data_url = \"data:audio/mp3;base64,\" + base64.b64encode(audio).decode()\n",
        "  style = '''<style>audio::-webkit-media-controls-current-time-display,\n",
        "    audio::-webkit-media-controls-time-remaining-display {display: none;}</style>'''\n",
        "  display.display(display.HTML(style + f'<audio controls style=\"width: {width}px; \">'\n",
        "                                       f'<source src=\"{data_url}\"></audio>'))\n",
        "\n",
        "def visualize_wav(waveform_or_filename):\n",
        "  if type(waveform_or_filename) == str:\n",
        "    waveform = get_waveform(waveform_or_filename)\n",
        "    #display.display(display.Audio(f'wav/{waveform_or_filename}'))\n",
        "    show_audio(f'wav/{waveform_or_filename}', width=760)\n",
        "  else:\n",
        "    waveform = waveform_or_filename\n",
        "  fig, (ax1, ax2) = plt.subplots(nrows=2, figsize=(8, 6), dpi=100,\n",
        "                                 gridspec_kw={'height_ratios': [1, 3]})\n",
        "  ax1.plot(np.arange(len(waveform))[::20], waveform[::20])\n",
        "  ax1.set_xlim(0, len(waveform))\n",
        "  ax2.imshow(np.log(1e-6 + get_spectrogram(waveform)), aspect='auto')\n",
        "  plt.show()\n",
        "\n",
        "def show_random_waveform_with_score(dataframe, score_range=None, score_std_range=None):\n",
        "  dataframe = dataframe[dataframe.file_exists]\n",
        "  if score_range is not None:\n",
        "    dataframe = dataframe[(dataframe.score_mean >= score_range[0]) & (dataframe.score_mean <= score_range[1])]\n",
        "  if score_std_range is not None:\n",
        "    dataframe = dataframe[(dataframe.score_std >= score_std_range[0]) & (dataframe.score_std <= score_std_range[1])]\n",
        "  if len(dataframe) == 0:\n",
        "    print('No samples')\n",
        "    return\n",
        "  row = dataframe.sample(1)\n",
        "  row.drop(columns=['subset', 'system', 'utterance', 'file_exists'], inplace=True)\n",
        "  display.display(row)\n",
        "  visualize_wav(row.file.tolist()[0])\n",
        "  \n",
        "def get_wave2vec2_model(device='cpu'):\n",
        "  bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "  return bundle.get_model().to(device)\n",
        "\n",
        "def get_wave2vec2_output(model, waveforms, lengths=None, output_layers=['aux']):\n",
        "  outputs = []\n",
        "  x = waveforms\n",
        "  transformer = model.encoder.transformer\n",
        "  if x.ndim != 2:\n",
        "    raise ValueError(\"Expected the input Tensor to be 2D (batch, time), but received {list(x.shape)}\")\n",
        "  #feature_extractor\n",
        "  x = x[:, None, :]  # (batch, channel==1, frame)\n",
        "  for i, layer in enumerate(model.feature_extractor.conv_layers):\n",
        "      x, lengths = layer(x, lengths)  # (batch, feature, frame)\n",
        "      if f'feature_extractor.conv_layers.{i}' in output_layers: outputs.append(x.transpose(1, 2))\n",
        "  x = x.transpose(1, 2)  # (batch, frame, feature)\n",
        "  if 'feature_extractor' in output_layers: outputs.append(x)\n",
        "  #encoder\n",
        "  x, mask = model.encoder._preprocess(x, lengths)\n",
        "  if 'feature_projection' in output_layers: outputs.append(x)\n",
        "  x = x + transformer.pos_conv_embed(x)\n",
        "  x = transformer.layer_norm(x)\n",
        "  x = transformer.dropout(x)\n",
        "  if 'transformer.preprocess' in output_layers: outputs.append(x)\n",
        "  for i, layer in enumerate(transformer.layers):\n",
        "      if not (transformer.training and torch.rand(1).item() <= transformer.layer_drop):\n",
        "          x = layer(x, attention_mask=None)\n",
        "      if f'transformer.layers.{i}' in output_layers: outputs.append(x)\n",
        "  if 'transformer' in output_layers: outputs.append(x)\n",
        "  #aux\n",
        "  x = model.aux(x)\n",
        "  if 'aux' in output_layers: outputs.append(x)\n",
        "  return outputs, lengths\n",
        "  #raise ValueError(f\"Unknown output_layer {output_layer}\")\n",
        "\n",
        "def get_wave2vec2_features_for_all_files(model, data, device, output_layer='aux', numpy=True):\n",
        "  results = {}\n",
        "  for i, row in tqdm(data.iterrows()):\n",
        "    if row.file_exists:\n",
        "      waveform = get_waveform(row.file)\n",
        "      with torch.no_grad():\n",
        "        outputs, lengths = get_wave2vec2_output(model, torch.Tensor(waveform[None]).to(device),\n",
        "                                                output_layers=[output_layer])\n",
        "      layer_output = outputs[0]\n",
        "      layer_output_no_batch = layer_output[0]\n",
        "      results[row.file] = layer_output_no_batch.cpu().detach()\n",
        "  if numpy:\n",
        "    results = {x: y.numpy() for x, y in results.items()}\n",
        "  return results"
      ],
      "metadata": {
        "id": "EZVisNgwdAxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Cлой feature_extractor.conv_layers.0: частота дискретизации 3199.8 гц, данные займут объем 195.776 Гб\n",
        "Cлой feature_extractor.conv_layers.1: частота дискретизации 1599.8 гц, данные займут объем 97.880 Гб\n",
        "Cлой feature_extractor.conv_layers.2: частота дискретизации 799.8 гц, данные займут объем 48.936 Гб\n",
        "Cлой feature_extractor.conv_layers.3: частота дискретизации 399.8 гц, данные займут объем 24.464 Гб\n",
        "Cлой feature_extractor.conv_layers.4: частота дискретизации 199.8 гц, данные займут объем 12.224 Гб\n",
        "Cлой feature_extractor.conv_layers.5: частота дискретизации 99.9 гц, данные займут объем 6.112 Гб\n",
        "Cлой feature_extractor.conv_layers.6: частота дискретизации 49.9 гц, данные займут объем 3.056 Гб\n",
        "Cлой feature_projection: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.preprocess: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.layers.0: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.layers.1: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.layers.2: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.layers.3: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.layers.4: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.layers.5: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.layers.6: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.layers.7: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.layers.8: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.layers.9: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой transformer.layers.10: частота дискретизации 49.9 гц, данные займут объем 4.584 Гб\n",
        "Cлой aux: частота дискретизации 49.9 гц, данные займут объем 0.191 Гб\n",
        "```\n"
      ],
      "metadata": {
        "id": "UTuWp4P9dzw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device = 'cuda'\n",
        "# wave2vec2_model = get_wave2vec2_model(device).eval()\n",
        "\n",
        "# features_with_time_axis = get_wave2vec2_features_for_all_files(wave2vec2_model, data, device='cuda',\n",
        "#                                           output_layer='feature_extractor.conv_layers.6')"
      ],
      "metadata": {
        "id": "uXqWWnQ-dIZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вариант 1: усреднение\n",
        "\n",
        "# features = {file: x.mean(axis=0)\n",
        "#             for file, x in features_with_time_axis.items()}"
      ],
      "metadata": {
        "id": "ERSIACGtfE_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вариант 2: среднее и среднекваратичное отклонение\n",
        "\n",
        "# features = {file: np.concatenate([x.mean(axis=0), x.std(axis=0)])\n",
        "#             for file, x in features_with_time_axis.items()}"
      ],
      "metadata": {
        "id": "f2CGazLQjH5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вариант 3: LSTM\n",
        "\n",
        "# ..."
      ],
      "metadata": {
        "id": "svXdgGlsk7JS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}